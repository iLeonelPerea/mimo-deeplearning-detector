# ComparaciÃ³n LÃ­nea por LÃ­nea: CÃ³digo MATLAB vs Python (Nuestro)

## 1. GeneraciÃ³n del Canal H

### MATLAB
```matlab
% training_2x2_detector_OneHot.m lÃ­nea 50
H = (1/sqrt(2))*(randn(Nr,Nt) + 1i*randn(Nr,Nt));
```
- **Canal ALEATORIO** por cada muestra de entrenamiento
- NormalizaciÃ³n: `1/sqrt(2)`
- Rayleigh fading: `CN(0, 1)`

### Python (Nuestro)
```python
# modelMIMO_2x2_4QAM_DoubleOneHot.py lÃ­neas 159-162
H = torch.tensor([[-0.90064 + 1j*0.43457, -0.99955 + 1j*0.029882],
                  [-0.1979 + 1j*0.98022, 0.44866 + 1j*0.8937]],
                 dtype=torch.complex64, device=device)
H = H / torch.abs(H)  # Normalize by element-wise magnitude
```
- **Canal FIJO** para todas las muestras
- NormalizaciÃ³n: element-wise `|h_ij|`

### ğŸ”´ DIFERENCIA #1: Canal aleatorio vs fijo
**Impacto:** En Matlab entrena con mÃºltiples realizaciones del canal (mÃ¡s realista), nosotros con un solo canal (sobreajuste posible).

---

## 2. GeneraciÃ³n de Ruido

### MATLAB
```matlab
% training_2x2_detector_OneHot.m lÃ­neas 51-52
n = (No/sqrt(2))*(randn(Nr,1) + 1i*randn(Nr,1));
n = (1/sqrt(SNR_l))*n;
```
Expandiendo:
```matlab
n = (No/sqrt(2)) * (randn + 1i*randn) * (1/sqrt(SNR))
```
Con `No = 1`:
```matlab
n = (1/sqrt(2)) * (randn + 1i*randn) * (1/sqrt(SNR))
n = (1/sqrt(2*SNR)) * (randn + 1i*randn)
```

Varianza del ruido:
- Parte real: `Var(real) = (1/(2*SNR)) * 1/2 = 1/(4*SNR)`
- Parte imag: `Var(imag) = (1/(2*SNR)) * 1/2 = 1/(4*SNR)`
- Varianza total: `ÏƒÂ²_n = 1/(4*SNR) + 1/(4*SNR) = 1/(2*SNR)`

### Python (Nuestro)
```python
# modelMIMO_2x2_4QAM_DoubleOneHot.py lÃ­neas 184-186
n_real = torch.randn(Nr, device=device) * np.sqrt(No/2)
n_imag = torch.randn(Nr, device=device) * np.sqrt(No/2)
n = torch.complex(n_real, n_imag)
```
Con `No = 1`:
```python
n = sqrt(1/2) * randn + 1j * sqrt(1/2) * randn
```

Varianza del ruido:
- Parte real: `Var(real) = 1/2 * 1 = 1/2`
- Parte imag: `Var(imag) = 1/2 * 1 = 1/2`
- Varianza total: `ÏƒÂ²_n = 1/2 + 1/2 = 1`

### ğŸ”´ DIFERENCIA #2: Varianza del ruido
| | En Matlab | Nuestro |
|---|-----------|---------|
| Varianza ruido | `1/(2*SNR)` | `1` (fijo) |
| Depende de SNR | âœ… SÃ­ | âŒ No |

**Impacto:** Nuestro ruido tiene varianza fija, En Matlab escala el ruido con SNR.

---

## 3. SNR de Entrenamiento

### MATLAB
```matlab
% training_2x2_detector_OneHot.m lÃ­nea 43
SNR_dB = 3; % SNR for add noise to training data
SNR_l = 10.^(SNR_dB./10);
```
- **SNR FIJO: 3 dB** para todas las muestras

### Python (Nuestro)
```python
# modelMIMO_2x2_4QAM_DoubleOneHot.py lÃ­neas 181-182
SNR_dB_sample = np.random.randint(1, 21)  # Random SNR between 1-20 dB
SNR_linear_sample = 10.0 ** (SNR_dB_sample / 10.0)
```
- **SNR ALEATORIO: 1-20 dB** por cada muestra

### ğŸ”´ DIFERENCIA #3: SNR de entrenamiento
**Impacto:** Nosotros entrenamos con mÃºltiples SNR (mÃ¡s robusto), En Matlab con un solo SNR (especializado).

---

## 4. Preprocesamiento de la SeÃ±al Recibida

### MATLAB - ENTRENAMIENTO
```matlab
% training_2x2_detector_OneHot.m lÃ­neas 53-55
r_x = H*sel_symbol.';     % Paso 1: Aplica canal
H_inv = pinv(H);          % Paso 2: Calcula Hâº
r_x = H_inv*r_x+n;        % Paso 3: Elimina canal, agrega ruido
```
**Resultado:** `r = x + n` (sin interferencia entre antenas)

### Python (Nuestro) - ENTRENAMIENTO
```python
# modelMIMO_2x2_4QAM_DoubleOneHot.py lÃ­nea 189
r_x = np.sqrt(SNR_linear_sample) * torch.matmul(H, selected_symbols) + n

# Con use_zf=False (por defecto)
r_processed = r_x  # lÃ­nea 197
```
**Resultado:** `r = sqrt(SNR) * H*x + n` (CON interferencia entre antenas)

### ğŸ”´ DIFERENCIA #4: Preprocesamiento (LA MÃS CRÃTICA)
| | En Matlab | Nuestro (actual) | Nuestro (antiguo con ZF) |
|---|-----------|------------------|--------------------------|
| Modelo | `r = x + n` | `r = sqrt(SNR)*H*x + n` | `r = x + Hâº*n` |
| Interferencia | âŒ No | âœ… SÃ­ | âŒ No |
| Ruido amplificado | âŒ No | âŒ No | âœ… SÃ­ |
| FÃ­sicamente realizable | âŒ No | âœ… SÃ­ | âœ… SÃ­ |

**Impacto CRÃTICO:**
- En Matlab elimina interferencia SIN amplificar ruido (solo simulaciÃ³n)
- Nuestro cÃ³digo actual mantiene interferencia (realista)
- Nuestro cÃ³digo antiguo eliminaba interferencia CON amplificaciÃ³n (ZF estÃ¡ndar)

---

## 5. NormalizaciÃ³n de SÃ­mbolos

### MATLAB
```matlab
% training_2x2_detector_OneHot.m lÃ­neas 28-31
M = 4; % 4-QAM
Xx = [-1 1];
Yy = [-1 1];
prod_cart = [Xx(:) Yy(:)];  % SÃ­mbolos sin normalizar
```
SÃ­mbolos: `{-1-1j, -1+1j, 1-1j, 1+1j}`

Potencia: `E[|x|Â²] = (1Â² + 1Â²) = 2`

### Python (Nuestro)
```python
# modelMIMO_2x2_4QAM_DoubleOneHot.py lÃ­neas 125-130
symbol_map = {
    0: -1 - 1j, 1: -1 + 1j,
    2: 1 - 1j,  3: 1 + 1j
}
symbol_combinations = torch.tensor([...], dtype=torch.complex64)
symbol_combinations = symbol_combinations / np.sqrt(2)  # lÃ­nea 180
```
SÃ­mbolos normalizados: `{-1/âˆš2 - 1j/âˆš2, ...}`

Potencia: `E[|x|Â²] = (1/2 + 1/2) = 1`

### ğŸ”´ DIFERENCIA #5: NormalizaciÃ³n de sÃ­mbolos
| | En Matlab | Nuestro |
|---|-----------|---------|
| SÃ­mbolos | `Â±1 Â± 1j` | `Â±1/âˆš2 Â± 1j/âˆš2` |
| Potencia | 2 | 1 (IEEE) |

**Impacto:** Escalamiento diferente de la seÃ±al.

---

## 6. Modelo de SeÃ±al Recibida

### MATLAB - ENTRENAMIENTO
```matlab
% Combinando todo:
H = (1/sqrt(2))*(randn(Nr,Nt) + 1i*randn(Nr,Nt));  % E[|h|Â²] = 1/2
x = sel_symbol.';                                   % E[|x|Â²] = 2
n = (1/sqrt(2*SNR))*(randn + 1i*randn);            % E[|n|Â²] = 1/(2*SNR)

r_temp = H*x;         % E[|H*x|Â²] = E[|h|Â²]*E[|x|Â²] = (1/2)*2 = 1
r_eq = Hâº * r_temp;   % E[|r_eq|Â²] â‰ˆ E[|x|Â²] = 2
r = r_eq + n;         % E[|r|Â²] â‰ˆ 2 + 1/(2*SNR)
```

**SNR efectivo:**
```
SNR_efectivo = E[|seÃ±al|Â²] / E[|ruido|Â²]
             = 2 / (1/(2*SNR))
             = 4*SNR
```

### Python (Nuestro)
```python
H = fixed_matrix / |H|              # NormalizaciÃ³n element-wise (no clear E[|h|Â²])
x = symbols / sqrt(2)               # E[|x|Â²] = 1
n = randn/sqrt(2) + 1j*randn/sqrt(2)  # E[|n|Â²] = 1

r = sqrt(SNR) * H*x + n
```

**SNR efectivo:**
```
SNR_efectivo = E[|sqrt(SNR)*H*x|Â²] / E[|n|Â²]
             = SNR * E[|H|Â²] * E[|x|Â²] / 1
             = SNR * E[|H|Â²] * 1
```

Con normalizaciÃ³n element-wise de H, `E[|H|Â²]` no estÃ¡ claro.

### ğŸ”´ DIFERENCIA #6: Modelo de seÃ±al completo
En Matlab y nosotros usamos modelos de potencia diferentes.

---

## 7. EvaluaciÃ³n BER

### MATLAB
```matlab
% BER_4QAM_MIMO_2x2_All.m lÃ­neas 102-105
Hinv = pinv(H);
H_eqz = H*Hinv;           % H * Hâº â‰ˆ I
r = H_eqz*x.' + n;        % r â‰ˆ x + n

% LÃ­nea 120: Alimenta a los modelos
Xinput = [real_r(1) imag_r(1) real_r(2) imag_r(2)];
```
**TambiÃ©n en evaluaciÃ³n elimina interferencia.**

### Python (Nuestro)
```python
# ber_4qam_mimo_2x2_all.py lÃ­nea 630
r = sqrt_SNR_j * (H_fixed @ x_transmitted) + n

# Con USE_ZF=False (lÃ­neas 396-399)
if use_zf and H_inv is not None:
    r_processed = H_inv @ r
else:
    r_processed = r  # Usa seÃ±al directa
```
**Por defecto mantiene interferencia.**

### ğŸ”´ DIFERENCIA #7: Consistencia entrenamiento-evaluaciÃ³n

| | Entrenamiento | EvaluaciÃ³n | Â¿Consistente? |
|---|---------------|------------|---------------|
| **En Matlab** | `r = x + n` | `r = x + n` | âœ… SÃ­ |
| **Nuestro (actual)** | `r = sqrt(SNR)*H*x + n` | `r = sqrt(SNR)*H*x + n` | âœ… SÃ­ |

Ambos somos consistentes, pero usamos **modelos diferentes**.

---

## 8. Orden de CaracterÃ­sticas de Entrada

### MATLAB
```matlab
% training_2x2_detector_OneHot.m lÃ­nea 56
X(i,:) = [real(r_x.') imag(r_x.')];
% Resultado: [real(r1) real(r2) imag(r1) imag(r2)]

% LÃ­nea 59-60: REORDENA
orden = [1,3,2,4]; % [real(x1) imag(x1) real(x2) imag(x2)]
X = X(:,orden);
% Resultado FINAL: [real(r1) imag(r1) real(r2) imag(r2)]
```

### Python (Nuestro)
```python
# modelMIMO_2x2_4QAM_DoubleOneHot.py lÃ­neas 199-202
X_data[i, 0] = r_processed[0].real
X_data[i, 1] = r_processed[0].imag
X_data[i, 2] = r_processed[1].real
X_data[i, 3] = r_processed[1].imag
# Resultado: [real(r1) imag(r1) real(r2) imag(r2)]
```

### âœ… SIN DIFERENCIA: Orden de caracterÃ­sticas
Ambos usan `[real(r1) imag(r1) real(r2) imag(r2)]`.

---

## 9. Arquitectura de Red Neuronal

### MATLAB - One-Hot
```matlab
% training_2x2_detector_OneHot.m lÃ­neas 70-92
% Input(4) -> Hidden(100) -> Output(16)
W1 = randn(hidden_size, input_size);
b1 = randn(hidden_size, 1);
W2 = randn(output_size, hidden_size);
b2 = randn(output_size, 1);

% Forward pass (lÃ­neas 137-143)
Z1 = W1*Xinput'+b1;
A1 = max(0,Z1);        % ReLU
Z2 = W2*A1+b2;
A2 = exp(Z2)./sum(exp(Z2));  % Softmax
```

### Python (Nuestro)
```python
# modelMIMO_2x2_4QAM_DoubleOneHot.py lÃ­neas 86-101
# Input(4) -> Hidden(100) -> Output(16)
self.layer1 = nn.Linear(input_size, hidden_size, bias=False)  # Sin bias!
self.layer2 = nn.Linear(hidden_size, output_size)

def forward(self, x):
    x = self.layer1(x)
    x = F.relu(x)
    x = self.layer2(x)
    return x  # Softmax se aplica despuÃ©s en CrossEntropyLoss
```

### ğŸ”´ DIFERENCIA #8: Bias en capa oculta
| | En Matlab | Nuestro |
|---|-----------|---------|
| Bias en capa 1 | âœ… SÃ­ | âŒ No |
| Bias en capa 2 | âœ… SÃ­ | âœ… SÃ­ |

**Impacto:** En Matlab tiene mÃ¡s parÃ¡metros entrenables.

---

## 10. ActivaciÃ³n de Salida

### MATLAB - One-Hot
```matlab
% training_2x2_detector_OneHot.m lÃ­nea 143
A2 = exp(Z2)./sum(exp(Z2));  % Softmax explÃ­cito
[~,idx_DL_1] = max(A2);
```

### Python (Nuestro) - Entrenamiento
```python
# modelMIMO_2x2_4QAM_DoubleOneHot.py lÃ­neas 215-217
criterion = nn.CrossEntropyLoss()  # CrossEntropyLoss incluye softmax
loss = criterion(outputs, labels)
```

### Python (Nuestro) - EvaluaciÃ³n
```python
# ber_4qam_mimo_2x2_all.py lÃ­neas 359-362
with torch.no_grad():
    outputs = model(x_input)
    probs = F.softmax(outputs, dim=1)
    _, predicted = torch.max(probs, 1)
```

### âœ… SIN DIFERENCIA: ActivaciÃ³n de salida
Ambos usan softmax para One-Hot.

---

## Resumen de Diferencias CrÃ­ticas

| # | Diferencia | En Matlab | Nuestro | Impacto |
|---|-----------|-----------|---------|---------|
| **1** | Canal | Aleatorio por muestra | Fijo | ğŸ”´ Alto |
| **2** | Varianza ruido | `1/(2*SNR)` | `1` fijo | ğŸ”´ Alto |
| **3** | SNR entrenamiento | Fijo (3 dB) | Aleatorio (1-20 dB) | ğŸŸ¡ Medio |
| **4** | **Preprocesamiento** | **`r = x + n`** | **`r = H*x + n`** | ğŸ”´ **CRÃTICO** |
| **5** | NormalizaciÃ³n sÃ­mbolos | `E[|x|Â²] = 2` | `E[|x|Â²] = 1` | ğŸŸ¡ Medio |
| **6** | Modelo de potencia | Custom | IEEE estÃ¡ndar | ğŸŸ¡ Medio |
| **7** | Consistencia train/eval | `r = x + n` ambos | `r = H*x + n` ambos | âœ… OK |
| **8** | Bias en capa oculta | SÃ­ | No | ğŸŸ¢ Bajo |

---

## ConclusiÃ³n: Â¿QuÃ© estÃ¡ causando la diferencia en resultados?

### Diferencia #4 es LA CLAVE ğŸ¯

**En Matlab:**
- Entrena con `r = x + n` (sin interferencia)
- EvalÃºa con `r = x + n` (sin interferencia)
- **Label Encoder y OHA funcionan** porque las antenas son independientes

**Nosotros:**
- Entrenamos con `r = sqrt(SNR)*H*x + n` (CON interferencia)
- Evaluamos con `r = sqrt(SNR)*H*x + n` (CON interferencia)
- **Label Encoder y OHA fallan** porque asumen independencia que no existe

---

## RecomendaciÃ³n

Para replicar los resultados de En Matlab, necesitamos implementar su preprocesamiento:

```python
# En entrenamiento y evaluaciÃ³n
r_temp = sqrt(SNR) * H @ x  # Aplica canal
H_inv = torch.linalg.pinv(H)
r = H_inv @ r_temp + n      # Elimina canal, luego agrega ruido
# Resultado: r = x + n
```

Esto hace que Label Encoder y OHA funcionen, pero **NO es fÃ­sicamente realizable** en sistemas reales (solo para simulaciÃ³n/investigaciÃ³n).

Alternativamente, podrÃ­amos usar Zero-Forcing estÃ¡ndar:

```python
# En entrenamiento y evaluaciÃ³n
r = sqrt(SNR) * H @ x + n   # Recibe con interferencia
H_inv = torch.linalg.pinv(H)
r_eq = H_inv @ r            # Aplica ZF
# Resultado: r_eq = x + H^+*n (con ruido amplificado)
```

Esto tambiÃ©n hace que Label Encoder y OHA funcionen, y **SÃ es fÃ­sicamente realizable** (receptores reales pueden hacer esto).
